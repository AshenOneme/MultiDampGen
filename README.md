<div align=center>
  
# MultiDampGen: A Self-Supervised Latent Diffusion Framework for Multiscale Energy-Dissipating Microstructure Generation
  
</div> 

<!-- é€†å‘è®¾è®¡ -->
* ## ğŸ§­ **_Overview of the workflow_**
<div align=center>
  <img width="1000" src="Figs/Abstract.png"/>   
  <img width="1000" src="Figs/Workflow.png"/>
   <div align=center><strong>Fig. 1. The workflow of MultiDampGen framework</strong></div>
</div><br>    

* ## âš›ï¸ **_Datasets & Pre-trained models_**
  The multiscale microstructure dataset encompasses a total of *__50,000 samples__*. The dataset utilized in this study, along with the pre-trained weights of MultiDampGen, can be accessed through the link provided below.      

[**ğŸ”—The damping microstructure dataset**](https://github.com/AshenOneme/MultiDampGen/releases/tag/Dataset)     
[**ğŸ”—The weights of the MultiDampGen**](https://github.com/AshenOneme/MultiDampGen/releases/tag/Weights)

<div align=center>
  
## ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ          

</div> 

<!-- T2C -->
* ## ğŸ§± **_TXT2CAE_**          
  The TXT2CAE plugin has been developed based on the ABAQUS-Python API, enabling the generation of three-dimensional finite element models from arbitrary patterns, along with automated mesh generation. Testing has demonstrated successful operation on *__ABAQUS versions 2018 to 2020__*.
<div align=center>
  <img width="1000" src="Figs/TXT2CAE.png"/>
   <div align=center><strong>Fig. 2. The TXT2CAE GUI</strong></div>
</div><br>   

<!-- Dataset -->
* ## ğŸ—ï¸ **_Dataset_**          
  A total of 50,000 sets of microstructural data were extracted, including yield strength, yield displacement, first stiffness, and second-order stiffness. The distribution relationships were subsequently plotted based on *__volume fraction__* and *__physical scale__*.
<div align=center>
  <img width="1000" src="Figs/Dataset.png"/>
   <div align=center><strong>Fig. 3. Distribution of mechanical properties</strong></div>
</div><br>  

<!-- Architecture of MultiDampGen -->
* ## ğŸ¦ **_Architecture of MultiDampGen_**          
  The network architecture of MultiDampGen is detailed as follows, with TopoFormer serving as a Variational Autoencoder (VAE) structure, RSV representing a residual network structure, and LDPM designed as a UNet structure with conditional inputs. Both the VAE and LDPM incorporate self-attention mechanisms to enhance their functionality.
<div align=center>
  <img width="600" src="Figs/TopoFormer.png"/>
   <div align=center><strong>Fig. 4. Architecture of TopoFormer</strong></div>
    <img width="600" src="Figs/RSV.png"/>
   <div align=center><strong>Fig. 5. Architecture of RSV</strong></div>
    <img width="600" src="Figs/LDPM.png"/>
   <div align=center><strong>Fig. 6. Architecture of LDPM</strong></div>
</div><br>  

<!-- Generation process -->
* ## ğŸ”¬ **_Generation process_**          
  The generation process of multiscale microstructures is illustrated in the figure, with the *__red line__* representing the specified mechanical performance demands. The scales of the microstructures are randomly determined, and the generation results at each timestep are evaluated through finite element analysis. It can be observed that the hysteretic performance, indicated by the *__blue line__*, progressively approaches the target demands.
<div align=center>
  <img width="1000" src="Figs/GenerationProcess.gif"/>
   <div align=center><strong>Fig. 7. The generation process</strong></div>
</div><br> 

<!-- Generation results -->
* ## ğŸš€ **_Generation results_**          
  Regardless of how extreme the specified mechanical properties or scales may be, it is possible to generate microstructures that meet the demands. Additionally, by employing a latent diffusion approach, the generation efficiency has been improved significantly, achieving a square factor increase compared to the Denoising Diffusion Probabilistic Model (DDPM).
<div align=center>
  <img width="1000" src="Figs/Results.png"/>
   <div align=center><strong>Fig. 8. The generation results</strong></div>
</div><br> 

<!-- Notes -->
* ## ğŸš€ **_Notes_**   

```Python
=================================================================================================================================================
Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Kernel Shape
=================================================================================================================================================
ClassConditionedUnet_M                        [28, 3, 32, 32]           [28, 3, 32, 32]           --                        --
â”œâ”€TimeEmbedding: 1-1                          [28]                      [28, 128]                 --                        --
â”‚    â””â”€Linear: 2-1                            [28, 128]                 [28, 128]                 16,512                    --
â”‚    â””â”€Swish: 2-2                             [28, 128]                 [28, 128]                 --                        --
â”‚    â””â”€Linear: 2-3                            [28, 128]                 [28, 128]                 16,512                    --
â”œâ”€Linear: 1-2                                 [28, 64]                  [28, 128]                 8,320                     --
â”œâ”€Linear: 1-3                                 [28, 1]                   [28, 128]                 256                       --
â”œâ”€ModuleList: 1-4                             --                        --                        --                        --
â”‚    â””â”€SwitchSequential: 2-4                  [28, 3, 32, 32]           [28, 64, 32, 32]          --                        --
â”‚    â”‚    â””â”€Conv2d: 3-1                       [28, 3, 32, 32]           [28, 64, 32, 32]          1,792                     [3, 3]
â”‚    â””â”€SwitchSequential: 2-5                  [28, 64, 32, 32]          [28, 64, 32, 32]          --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-2           [28, 64, 32, 32]          [28, 64, 32, 32]          98,880                    --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-3           [28, 64, 32, 32]          [28, 64, 32, 32]          98,880                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-4          [28, 64, 32, 32]          [28, 64, 32, 32]          35,320                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-5          [28, 64, 32, 32]          [28, 64, 32, 32]          35,320                    --
â”‚    â””â”€SwitchSequential: 2-6                  [28, 64, 32, 32]          [28, 64, 32, 32]          --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-6           [28, 64, 32, 32]          [28, 64, 32, 32]          98,880                    --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-7           [28, 64, 32, 32]          [28, 64, 32, 32]          98,880                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-8          [28, 64, 32, 32]          [28, 64, 32, 32]          35,320                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-9          [28, 64, 32, 32]          [28, 64, 32, 32]          35,320                    --
â”‚    â””â”€SwitchSequential: 2-7                  [28, 64, 32, 32]          [28, 128, 16, 16]         --                        --
â”‚    â”‚    â””â”€Conv2d: 3-10                      [28, 64, 32, 32]          [28, 128, 16, 16]         73,856                    [3, 3]
â”‚    â””â”€SwitchSequential: 2-8                  [28, 128, 16, 16]         [28, 128, 16, 16]         --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-11          [28, 128, 16, 16]         [28, 128, 16, 16]         345,216                   --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-12          [28, 128, 16, 16]         [28, 128, 16, 16]         345,216                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-13         [28, 128, 16, 16]         [28, 128, 16, 16]         91,120                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-14         [28, 128, 16, 16]         [28, 128, 16, 16]         91,120                    --
â”‚    â””â”€SwitchSequential: 2-9                  [28, 128, 16, 16]         [28, 128, 16, 16]         --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-15          [28, 128, 16, 16]         [28, 128, 16, 16]         345,216                   --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-16          [28, 128, 16, 16]         [28, 128, 16, 16]         345,216                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-17         [28, 128, 16, 16]         [28, 128, 16, 16]         91,120                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-18         [28, 128, 16, 16]         [28, 128, 16, 16]         91,120                    --
â”‚    â””â”€SwitchSequential: 2-10                 [28, 128, 16, 16]         [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€Conv2d: 3-19                      [28, 128, 16, 16]         [28, 256, 8, 8]           295,168                   [3, 3]
â”‚    â””â”€SwitchSequential: 2-11                 [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-20          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-21          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-22         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-23         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â””â”€SwitchSequential: 2-12                 [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-24          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-25          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-26         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-27         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â””â”€SwitchSequential: 2-13                 [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€Conv2d: 3-28                      [28, 256, 8, 8]           [28, 256, 8, 8]           590,080                   [3, 3]
â”‚    â””â”€SwitchSequential: 2-14                 [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-29          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-30          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-31         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-32         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â””â”€SwitchSequential: 2-15                 [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-33          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-34          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-35         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-36         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”œâ”€SwitchSequential: 1-5                       [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â””â”€UNet_ResidualBlock: 2-16               [28, 256, 8, 8]           [28, 256, 8, 8]           33,024                    --
â”‚    â”‚    â””â”€GroupNorm: 3-37                   [28, 256, 8, 8]           [28, 256, 8, 8]           512                       --
â”‚    â”‚    â””â”€Conv2d: 3-38                      [28, 256, 8, 8]           [28, 256, 8, 8]           590,080                   [3, 3]
â”‚    â”‚    â””â”€Linear: 3-39                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-40                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-41                      [28, 128]                 [28, 256]                 (recursive)               --
â”‚    â”‚    â””â”€GroupNorm: 3-42                   [28, 256, 8, 8]           [28, 256, 8, 8]           512                       --
â”‚    â”‚    â””â”€Conv2d: 3-43                      [28, 256, 8, 8]           [28, 256, 8, 8]           590,080                   [3, 3]
â”‚    â”‚    â””â”€Identity: 3-44                    [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â””â”€UNet_ResidualBlock: 2-17               [28, 256, 8, 8]           [28, 256, 8, 8]           33,024                    --
â”‚    â”‚    â””â”€GroupNorm: 3-45                   [28, 256, 8, 8]           [28, 256, 8, 8]           512                       --
â”‚    â”‚    â””â”€Conv2d: 3-46                      [28, 256, 8, 8]           [28, 256, 8, 8]           590,080                   [3, 3]
â”‚    â”‚    â””â”€Linear: 3-47                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-48                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-49                      [28, 128]                 [28, 256]                 (recursive)               --
â”‚    â”‚    â””â”€GroupNorm: 3-50                   [28, 256, 8, 8]           [28, 256, 8, 8]           512                       --
â”‚    â”‚    â””â”€Conv2d: 3-51                      [28, 256, 8, 8]           [28, 256, 8, 8]           590,080                   [3, 3]
â”‚    â”‚    â””â”€Identity: 3-52                    [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â””â”€UNet_AttentionBlock: 2-18              [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€GroupNorm: 3-53                   [28, 256, 8, 8]           [28, 256, 8, 8]           512                       --
â”‚    â”‚    â””â”€Linear: 3-54                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-55                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-56                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-57                      [28, 64, 256]             [28, 64, 360]             92,520                    --
â”‚    â”‚    â””â”€Linear: 3-58                      [28, 64, 120]             [28, 64, 256]             30,976                    --
â”‚    â””â”€UNet_AttentionBlock: 2-19              [28, 256, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€GroupNorm: 3-59                   [28, 256, 8, 8]           [28, 256, 8, 8]           512                       --
â”‚    â”‚    â””â”€Linear: 3-60                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-61                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-62                      [28, 128]                 [28, 256]                 33,024                    --
â”‚    â”‚    â””â”€Linear: 3-63                      [28, 64, 256]             [28, 64, 360]             92,520                    --
â”‚    â”‚    â””â”€Linear: 3-64                      [28, 64, 120]             [28, 64, 256]             30,976                    --
â”œâ”€ModuleList: 1-6                             --                        --                        --                        --
â”‚    â””â”€SwitchSequential: 2-20                 [28, 512, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-65          [28, 512, 8, 8]           [28, 256, 8, 8]           2,001,920                 --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-66          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-67         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-68         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â””â”€SwitchSequential: 2-21                 [28, 512, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-69          [28, 512, 8, 8]           [28, 256, 8, 8]           2,001,920                 --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-70          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-71         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-72         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â””â”€SwitchSequential: 2-22                 [28, 512, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€ConvTranspose2d: 3-73             [28, 512, 8, 8]           [28, 256, 8, 8]           1,179,904                 [3, 3]
â”‚    â””â”€SwitchSequential: 2-23                 [28, 512, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-74          [28, 512, 8, 8]           [28, 256, 8, 8]           2,001,920                 --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-75          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-76         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-77         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â””â”€SwitchSequential: 2-24                 [28, 512, 8, 8]           [28, 256, 8, 8]           --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-78          [28, 512, 8, 8]           [28, 256, 8, 8]           2,001,920                 --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-79          [28, 256, 8, 8]           [28, 256, 8, 8]           1,280,256                 --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-80         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-81         [28, 256, 8, 8]           [28, 256, 8, 8]           223,080                   --
â”‚    â””â”€SwitchSequential: 2-25                 [28, 512, 8, 8]           [28, 256, 16, 16]         --                        --
â”‚    â”‚    â””â”€ConvTranspose2d: 3-82             [28, 512, 8, 8]           [28, 256, 16, 16]         2,097,408                 [4, 4]
â”‚    â””â”€SwitchSequential: 2-26                 [28, 384, 16, 16]         [28, 128, 16, 16]         --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-83          [28, 384, 16, 16]         [28, 128, 16, 16]         689,920                   --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-84          [28, 128, 16, 16]         [28, 128, 16, 16]         345,216                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-85         [28, 128, 16, 16]         [28, 128, 16, 16]         91,120                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-86         [28, 128, 16, 16]         [28, 128, 16, 16]         91,120                    --
â”‚    â””â”€SwitchSequential: 2-27                 [28, 256, 16, 16]         [28, 128, 16, 16]         --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-87          [28, 256, 16, 16]         [28, 128, 16, 16]         525,824                   --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-88          [28, 128, 16, 16]         [28, 128, 16, 16]         345,216                   --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-89         [28, 128, 16, 16]         [28, 128, 16, 16]         91,120                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-90         [28, 128, 16, 16]         [28, 128, 16, 16]         91,120                    --
â”‚    â””â”€SwitchSequential: 2-28                 [28, 256, 16, 16]         [28, 128, 31, 31]         --                        --
â”‚    â”‚    â””â”€ConvTranspose2d: 3-91             [28, 256, 16, 16]         [28, 128, 31, 31]         295,040                   [3, 3]
â”‚    â””â”€SwitchSequential: 2-29                 [28, 192, 32, 32]         [28, 64, 32, 32]          --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-92          [28, 192, 32, 32]         [28, 64, 32, 32]          185,216                   --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-93          [28, 64, 32, 32]          [28, 64, 32, 32]          98,880                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-94         [28, 64, 32, 32]          [28, 64, 32, 32]          35,320                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-95         [28, 64, 32, 32]          [28, 64, 32, 32]          35,320                    --
â”‚    â””â”€SwitchSequential: 2-30                 [28, 128, 32, 32]         [28, 64, 32, 32]          --                        --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-96          [28, 128, 32, 32]         [28, 64, 32, 32]          144,128                   --
â”‚    â”‚    â””â”€UNet_ResidualBlock: 3-97          [28, 64, 32, 32]          [28, 64, 32, 32]          98,880                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-98         [28, 64, 32, 32]          [28, 64, 32, 32]          35,320                    --
â”‚    â”‚    â””â”€UNet_AttentionBlock: 3-99         [28, 64, 32, 32]          [28, 64, 32, 32]          35,320                    --
â”‚    â””â”€SwitchSequential: 2-31                 [28, 128, 32, 32]         [28, 3, 32, 32]           --                        --
â”‚    â”‚    â””â”€ConvTranspose2d: 3-100            [28, 128, 32, 32]         [28, 3, 32, 32]           3,459                     [3, 3]
=================================================================================================================================================
Total params: 39,746,195
Trainable params: 39,746,195
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 112.19
=================================================================================================================================================
Input size (MB): 0.35
Forward/backward pass size (MB): 2100.31
Params size (MB): 155.81
Estimated Total Size (MB): 2256.48
=================================================================================================================================================
```
